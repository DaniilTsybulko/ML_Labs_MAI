# Введение в машинное обучение

Машинное обучение — это наука о нахождении закономерностей в данных с помощью алгоритмов, позволяющих строить модели на основе примеров. Этот подход полезен там, где нет точных решений, но есть накопленные данные, например, для прогнозирования прибыли ресторанов или поведения клиентов.

## Задачи машинного обучения

1. **Обучение с учителем:**
   - **Регрессия** — прогнозирование численных данных (например, прибыль).
   - **Классификация** — предсказание категорий (кликнет ли пользователь на рекламу).
2. **Обучение без учителя:**
   - **Кластеризация** — разделение объектов на группы.
   - **Оценка плотности** — поиск аномалий.
   - **Понижение размерности** — упрощение данных.
3. **Обучение с подкреплением** — оптимизация действий для максимизации награды (например, управление беспилотным автомобилем).

## Ключевые этапы работы

1. Постановка задачи.
2. Выделение признаков.
3. Формирование выборки.
4. Выбор функционала ошибки.
5. Предобработка данных.
6. Обучение модели.
7. Оценка качества.



## Примеры применения

### Преимущества:
- Выявление скрытых закономерностей.
- Прогнозирование сложных зависимостей.
- Автоматизация трудоёмких задач (например, классификация овощей по качеству).

### Условия успешного использования:
- Достаточный объём данных.
- Сложность зависимости между признаками и целевой переменной.
- Невозможность построения точных формул.

## Линейные модели

Линейные модели представляют собой один из базовых инструментов машинного обучения. Они описываются формулой:

$$
\begin{equation}
a(x) = w_0 + \sum_{j=1}^{d} w_j x_j,
\end{equation}
$$

где:
- $w_j$— веса модели,
- $w_0$— свободный коэффициент,
- $x_j$— признаки объекта.  

Такая форма позволяет выразить прогноз как скалярное произведение вектора признаков и весов.

### Преимущества линейных моделей:
1. **Простота обучения** — вычисления происходят быстро.
2. **Устойчивость** — ограниченное количество параметров снижает риск переобучения.
3. **Интерпретируемость** — вклад каждого признака легко анализировать.

Однако линейные модели предполагают линейную зависимость между признаками и целевой переменной, что ограничивает их применимость для сложных зависимостей.



## Области применения и обработка данных

### 1. Категориальные признаки:
- Кодируются через **one-hot представление** — преобразование признака в несколько бинарных переменных.  
  Пример: если признак принимает значения {A, B, C}, он преобразуется в три бинарных признака (один из которых равен единице, остальные — нулю).

### 2. Работа с текстами:
- Метод "мешок слов" (bag of words): текст представляется как набор уникальных слов, где каждый признак отражает частоту появления конкретного слова в тексте.

### 3. Бинаризация числовых признаков:
- Разбиение данных на интервалы. Каждый интервал представляется бинарным признаком. Это позволяет учитывать нелинейные зависимости.



## Метрики оценки качества моделей

### 1. Среднеквадратичная ошибка (MSE):

$$
MSE = \frac{1}{\ell} \sum_{i=1}^{\ell} (a(x_i) - y_i)^2.
$$

- Подходит для оптимизации благодаря дифференцируемости.
- Чувствительна к выбросам.
- Часто используется корень MSE (RMSE) для сохранения единиц измерения.

### 2. Средняя абсолютная ошибка (MAE):

$$
MAE = \frac{1}{\ell} \sum_{i=1}^{\ell} |a(x_i) - y_i|.
$$

- Устойчивее к выбросам, чем MSE.
- Труднее оптимизируется.

### 3. Коэффициент детерминации ($R^2$):

$$
R^2 = 1 - \frac{\sum_{i=1}^{\ell} (a(x_i) - y_i)^2}{\sum_{i=1}^{\ell} (y_i - \bar{y})^2}.
$$

- $R^2$, близкий к 1, указывает на хорошую модель, а близкий к 0 — на слабую.

### 4. Гибридные функции потерь:

- **Huber Loss** — комбинирует свойства MSE и MAE:

$$
L_\delta(y, a) = 
\begin{cases} 
\frac{1}{2}(y - a)^2, & \text{если } |y - a| < \delta, \\
\delta (|y - a| - \frac{1}{2}\delta), & \text{иначе}.
\end{cases}
$$

- **Log-Cosh Loss** — мягче штрафует большие ошибки:

$$
L(y, a) = \log(\cosh(y - a)).
$$

### 5. Среднеквадратичная логарифмическая ошибка (MSLE):

$$
MSLE = \frac{1}{\ell} \sum_{i=1}^{\ell} (\log(a(x_i) + 1) - \log(y_i + 1))^2.
$$

- Применяется для неотрицательных целевых переменных.

### 6. Процентные ошибки (MAPE и SMAPE):
- **MAPE** измеряет среднюю абсолютную процентную ошибку:

$$
MAPE = \frac{1}{\ell} \sum_{i=1}^{\ell} \left|\frac{y_i - a(x_i)}{y_i}\right|.
$$

- **SMAPE** нормализует ошибку на среднее значение прогнозов и ответов:

$$
SMAPE = \frac{|y - a|}{(|y| + |a|)/2}.
$$

### 7. Квантильная функция потерь:
- Используется для задач с разной ценностью ошибок:

$$
Q(a, X) = \sum_{i=1}^{\ell} \rho_\tau(y_i - a(x_i)),
$$

где $\rho_\tau(z)$акцентирует внимание на занижениях или завышениях.

# Переобучение

Переобучение возникает, когда модель чрезмерно подстраивается под обучающую выборку, теряя способность обобщать закономерности на новые данные. Это часто проявляется при использовании слишком сложных моделей, например, с большим количеством признаков или их высокими степенями.  

**Пример:** модель с признаками $\{x, x^2, \dots, x^{15}\}$может точно описать обучающую выборку, но плохо справляется с предсказанием новых данных, так как учитывает случайный шум.

### Методы борьбы с переобучением:
- **Сужение класса моделей:** выбираются модели меньшей сложности.
- **Регуляризация:** вводится штраф за большие значения коэффициентов модели, чтобы уменьшить влияние случайного шума.



# Оценивание качества моделей

Качество моделей оценивается с помощью отложенной выборки.  

### Данные делятся на:
1. **Обучающую выборку** — используется для настройки модели.
2. **Контрольную выборку** — предназначена для проверки качества модели.

### Кросс-валидация:
Для повышения надёжности используется метод кросс-валидации:
1. Данные делятся на $k$частей (блоков).
2. Модель обучается на $k-1$блоках и тестируется на оставшемся.
3. Процесс повторяется $k$раз, каждый раз меняя тестовый блок.
4. Итоговое качество модели вычисляется как среднее по всем итерациям.

### После кросс-валидации возможны два подхода:
1. **Обучение на всей выборке:** модель обучается на всех доступных данных, чтобы извлечь максимум информации.
2. **Композиция моделей:** объединение моделей из каждого шага кросс-валидации (например, усреднение прогнозов в регрессии).



# Обучение линейной регрессии

Линейная регрессия обучается путём минимизации среднеквадратичной ошибки (MSE):

$$
\frac{1}{\ell} \sum_{i=1}^\ell (\langle w, x_i \rangle - y_i)^2 \to \min_w,
$$

где:
- $X$— матрица признаков,
- $y$— вектор целевых переменных,
- $w$— вектор параметров модели.

### Решение задачи:
Представлено в матричном виде:

$$
w = (X^TX)^{-1}X^Ty.
$$

### Проблемы аналитического решения:
1. **Сложность вычислений:** обращение матрицы требует $O(d^3)$операций, что непрактично для больших $d$.
2. **Плохо обусловленная матрица:** если $X^TX$близка к вырожденной, результат становится нестабильным.  
   **Решение:** регуляризация или численные методы.



# Градиентный спуск

Градиентный спуск — это итеративный метод оптимизации, подходящий для задач, где аналитическое решение недоступно.  

### Шаги алгоритма:

$$
w^{(k)} = w^{(k-1)} - \eta_k \nabla Q(w^{(k-1)}),
$$

где:
- $Q(w)$— функция ошибки,
- $\eta_k$— длина шага,
- $\nabla Q$— градиент функции ошибки.

### Основные свойства градиента:
1. Градиент показывает направление наибольшего роста функции.
2. Антиградиент ($-\nabla Q$) указывает направление наискорейшего уменьшения.
3. Градиент ортогонален линиям уровня функции.

### Выбор длины шага ($\eta_k$):
- **Слишком большой шаг** может привести к нестабильности (перепрыгиванию минимума).
- **Слишком маленький шаг** замедляет сходимость.
- На практике используются:
  - Адаптивные шаги,
  - Убывающий шаг, например $\eta_k = \frac{1}{k}$.

# Методы оценивания градиента

Для ускорения работы вместо полного градиента для всей выборки:

$$
\nabla Q(w) = \frac{1}{\ell} \sum_{i=1}^\ell \nabla q_i(w),
$$

применяются приближённые методы:

### 1. Стохастический градиентный спуск (SGD):
- Градиент вычисляется на одном случайно выбранном объекте:

$$
\nabla Q(w) \approx \nabla q_i(w).
$$

- **Преимущества:** высокая скорость итерации.
- **Недостатки:** менее точен, требует убывающего шага для сходимости.

### 2. Mini-batch градиентный спуск:
- Использует подвыборки данных (пакеты) для оценки градиента:

$$
\nabla Q(w) \approx \frac{1}{n} \sum_{j=1}^n \nabla q_{i_j}(w),
$$

  где $n$— размер пакета.

### 3. Stochastic Average Gradient (SAG):
- Хранит все вычисленные ранее градиенты.
- Обновляет градиент только для одного объекта на каждом шаге.
- **Преимущество:** ускоряет сходимость.
- **Недостаток:** требует памяти для хранения всех градиентов.

#### Модификации градиентного спуска
1. **Метод инерции (Momentum):**
   - Уменьшает осцилляции, усредняя градиенты нескольких итераций:

$$
h_k = \alpha h_{k-1} + \eta_k \nabla Q(w^{(k-1)}),
$$

где $\alpha$— коэффициент инерции.
   - Позволяет быстрее находить минимум.

2. **AdaGrad:**
   - Адаптирует длину шага для каждого параметра:

$$
w_j^{(k)} = w_j^{(k-1)} - \frac{\eta}{\sqrt{G_{k,j} + \epsilon}} \nabla_j Q(w^{(k-1)})
$$

где $G_{k,j}$— накопленные квадраты градиентов, а $\epsilon$предотвращает деление на ноль.

3. **RMSprop:**
   - Вводит экспоненциальное затухание градиентов, чтобы шаги не замедлялись слишком сильно:

$$
G_{k,j} = \alpha G_{k-1,j} + (1 - \alpha)(\nabla_j Q(w^{(k-1)}))^2.
$$

4. **Adam:**
   - Комбинирует идеи Momentum и RMSprop, обеспечивая быструю и стабильную сходимость.

## Линейные модели классификации

### Формализация
Линейная модель классификации для задачи бинарной классификации определяется следующим образом:

$$
a(x) = \text{sign} \left( \langle w, x \rangle + w_0 \right) = \text{sign} \left( \sum_{j=1}^d w_j x_j + w_0 \right),
$$

где $w $— вектор весов, $w_0 $— сдвиг (bias). Модель разделяет пространство объектов гиперплоскостью, относит полупространства к положительному или отрицательному классу.

Если в признаках добавляется константа $x_{d+1} = 1 $, сдвиг $w_0 $становится ненужным, и модель принимает вид:

$$
a(x) = \text{sign} \langle w, x \rangle.
$$

## Обучение линейных классификаторов

### Основной функционал
Для обучения используется доля неправильных ответов:

$$
Q(a, X) = \frac{1}{\ell} \sum_{i=1}^\ell \left[ \text{sign} \langle w, x_i \rangle \neq y_i \right] \to \min_w.
$$

Этот функционал является дискретным и сложен для минимизации. Для решения задачи вводят **отступы**:

$$
M_i = y_i \langle w, x_i \rangle.
$$

Функционал можно переписать через отступы:

$$
Q(a, X) = \frac{1}{\ell} \sum_{i=1}^\ell [M_i < 0].
$$

Для минимизации используют **гладкие верхние оценки** на функцию потерь $L(M) = [M < 0] $, например:
- Логистическая: $L(M) = \log(1 + e^{-M})$,
- Метод опорных векторов: $L(M) = \max(0, 1 - M)$,
- Персептрон: $L(M) = \max(0, -M)$.

## Метрики качества классификации

### 1. Доля правильных ответов
Определяется как:

$$
\text{accuracy} = \frac{1}{\ell} \sum_{i=1}^\ell [a(x_i) = y_i].
$$

Недостаток: игнорирует несбалансированность классов. Для анализа вводят **относительное уменьшение ошибки**.

### 2. Матрица ошибок
Объекты классификации разделяют на категории: 
- $\text{TP}$(True Positive), $\text{FP}$(False Positive), $\text{FN}$(False Negative), $\text{TN}$(True Negative).

Отсюда вводят:
- Точность (precision):

$$
\text{precision} = \frac{\text{TP}}{\text{TP} + \text{FP}},
$$

- Полноту (recall):

$$
\text{recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}.
$$

Также используется **F-мера** — гармоническое среднее точности и полноты:

$$
F = \frac{2 \cdot \text{precision} \cdot \text{recall}}{\text{precision} + \text{recall}}.
$$

### 3. ROC-кривая и AUC-ROC
ROC-кривая строится в координатах:
- False Positive Rate (FPR): 

$$
\text{FPR} = \frac{\text{FP}}{\text{FP} + \text{TN}},
$$

- True Positive Rate (TPR): 

$$
\text{TPR} = \frac{\text{TP}}{\text{TP} + \text{FN}}.
$$

Площадь под ROC-кривой $( \text{AUC-ROC} $) измеряет обобщённое качество алгоритма. В задачах кредитного скоринга применяется **индекс Джини**:

$$
\text{Gini} = 2 \cdot \text{AUC} - 1.
$$

### 4. Precision-Recall кривая и AUC-PR
Используется для несбалансированных классов. Precision-Recall кривая оценивает точность и полноту, строя их зависимость от порога классификации. Площадь под PR-кривой $( \text{AUC-PR} )$аппроксимируется через среднюю точность:

$$
\text{AUC-PR} = \frac{1}{\ell_+} \sum_{k=1}^\ell [y_k = 1] \cdot \text{precision@k}.
$$

## Логистическая регрессия

### Оценивание вероятностей

Логистическая регрессия строится на основе логистической функции потерь. Основная задача — корректно оценивать вероятность принадлежности объекта к классу $+1 $.

Пусть вероятность принадлежности объекта $x $к классу $+1 $обозначена как $p(y = +1 | x) $. Для алгоритма $b(x) $, возвращающего вероятности, минимизация функционала должна приводить к:

$$
\arg\min_{b \in \mathbb{R}} \frac{1}{n} \sum_{i=1}^n L(y_i, b) \approx p(y = +1 | x).
$$

Пример: логарифмическая функция потерь позволяет корректно оценивать вероятности. Если объект $x $встречается $ n $ раз, матожидание ошибки имеет вид:

$$
\arg\min_{b \in \mathbb{R}} \left( \frac{k}{n} L(1, b) + \frac{n-k}{n} L(-1, b) \right) = \frac{k}{n},
$$

где $ k $ — количество объектов класса $ +1 $.



### Правдоподобие и логистические потери

Логистическая функция потерь ($ \text{log-loss} $) основана на максимизации правдоподобия выборки:

$$
Q(a, X) = \prod_{i=1}^\ell b(x_i)^{[y_i=+1]} (1 - b(x_i))^{[y_i=-1]}.
$$

Логарифм правдоподобия удобен для оптимизации:

$$
-\sum_{i=1}^\ell \left( [y_i = +1] \log b(x_i) + [y_i = -1] \log(1 - b(x_i)) \right) \to \min.
$$

Эта функция потерь оптимизирует правдоподобие выборки и обеспечивает корректные оценки вероятности.



### Логистическая регрессия

Логистическая регрессия преобразует линейную модель через сигмоидную функцию:

$$
b(x) = \sigma(\langle w, x \rangle), \quad \sigma(z) = \frac{1}{1 + \exp(-z)}.
$$

Скалярное произведение $ \langle w, x \rangle $ интерпретируется как логарифм отношения вероятностей классов ($ \text{log-odds} $):

$$
\langle w, x \rangle = \log \frac{p(y = +1 | x)}{p(y = -1 | x)}.
$$

Логистические потери можно выразить следующим образом:

$$
-\sum_{i=1}^\ell \log(1 + \exp(-y_i \langle w, x_i \rangle)).
$$

Оптимизация этого функционала определяет модель логистической регрессии.



## Метод опорных векторов

Метод опорных векторов (SVM) основан на максимизации разделяющего зазора между классами.

### Разделимый случай

Если выборка линейно разделима, задача SVM записывается как:

$$
\begin{aligned}
&\frac{1}{2} \|w\|^2 \to \min_{w, b}, \\
&y_i (\langle w, x_i \rangle + b) \geq 1, \quad i = 1, \ldots, \ell.
\end{aligned}
$$

Максимизация ширины разделяющей полосы улучшает обобщающую способность классификатора.

### Неразделимый случай

Если выборка не разделима, вводятся штрафы за нарушения ($ \xi_i > 0 $):

$$
y_i (\langle w, x_i \rangle + b) \geq 1 - \xi_i, \quad \xi_i \geq 0.
$$

Оптимизационная задача принимает вид:

$$
\frac{1}{2} \|w\|^2 + C \sum_{i=1}^\ell \xi_i \to \min_{w, b, \xi}.
$$

Параметр $C$регулирует баланс между максимизацией отступа и минимизацией штрафов.



### Сведение к безусловной задаче

Штрафы $\xi_i $можно выразить через кусочно-линейную функцию потерь ($\text{hinge loss} $):

$$
\xi_i = \max(0, 1 - y_i (\langle w, x_i \rangle + b)).
$$

Тогда функционал становится:

$$
\frac{1}{2} \|w\|^2 + C \sum_{i=1}^\ell \max(0, 1 - y_i (\langle w, x_i \rangle + b)) \to \min_{w, b}.
$$

Этот функционал использует верхнюю оценку на долю ошибок с добавлением регуляризации.

## Многоклассовая классификация

### Сведение к серии бинарных задач

1. **Один против всех (One-vs-All):**
   - Обучается $K$ классификаторов $b_1(x), \ldots, b_K(x)$, каждый из которых отличает один класс от остальных.
   - Итоговый классификатор выбирает класс с наибольшей уверенностью:

$$
a(x) = \arg\max_{k \in \{1, \ldots, K\}} b_k(x).
$$

2. **Все против всех (All-vs-All):**
   - Обучается $\binom{K}{2}$ классификаторов $a_{ij}(x)$, каждый из которых различает пару классов $i$ и $j$.
   - Класс определяется большинством голосов.



### Многоклассовая логистическая регрессия

- Логистическая регрессия обобщается с использованием оператора **SoftMax**:

$$
\text{SoftMax}(z_1, \ldots, z_K) = \left( \frac{\exp(z_1)}{\sum_{k=1}^K \exp(z_k)}, \ldots, \frac{\exp(z_K)}{\sum_{k=1}^K \exp(z_k)} \right).
$$

- Вероятность принадлежности класса $k$:

$$
P(y = k | x, w) = \frac{\exp(\langle w_k, x \rangle + w_{0k})}{\sum_{j=1}^K \exp(\langle w_j, x \rangle + w_{0j})}.
$$

- Обучение происходит методом максимального правдоподобия.



### Многоклассовый метод опорных векторов (SVM)

1. **Функция потерь:**

$$
\max_k \{ \langle w_k, x \rangle + 1 - [k = y(x)] \} - \langle w_{y(x)}, x \rangle.
$$

   Потери равны нулю, если разрыв между правильным и другими классами превышает 1.

2. **Линейно разделимая выборка:**
   - Оптимизация максимального отступа (аналог бинарного SVM):

$$
\frac{1}{2} \|W\|^2 \to \min_W, \quad \langle w_{y_i}, x_i \rangle + [y_i = k] - \langle w_k, x_i \rangle > 1.
$$

3. **Неразделимая выборка:**
   - Добавляются штрафы $\xi_i > 0$:

$$
\frac{1}{2} \|W\|^2 + C \sum_{i=1}^\ell \xi_i \to \min_{W, \xi}.
$$



### Метрики качества многоклассовой классификации

Используются микро- и макро-усреднения:
- **Микро-усреднение:** усреднение характеристик (TP, FP и т.д.) по всем классам.
- **Макро-усреднение:** усреднение метрик для каждого класса.

Пример: точность в микро- и макро-усреднении:
- Микро:

$$
\text{precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}.
$$

- Макро:

$$
\text{precision} = \frac{1}{K} \sum_{k=1}^K \frac{\text{TP}_k}{\text{TP}_k + \text{FP}_k}.
$$



## Классификация с пересекающимися классами (Multi-label)

### Подходы к решению

1. **Независимая классификация (Binary Relevance):**
   - Обучается $K$ независимых классификаторов $a_1(x), \ldots, a_K(x)$.

2. **Стекинг классификаторов:**
   - Прогнозы базовых моделей $b_k(x)$ используются в качестве признаков для обучения новых моделей $a_k(x')$.

3. **Трансформация пространства ответов:**
   - Используется сингулярное разложение матрицы ответов $Y$:

$$
Y = U \Sigma V^\top.
$$

   - Сжимаются ответы до $M$-мерного пространства.



### Метрики качества

1. **Хэмминговая метрика:**

$$
\text{hamming}(a, X) = \frac{1}{\ell} \sum_{i=1}^\ell \frac{|Y_i \setminus Z_i| + |Z_i \setminus Y_i|}{K}.
$$

2. Обобщённые метрики:
   - Точность:

$$
\text{accuracy}(a, X) = \frac{1}{\ell} \sum_{i=1}^\ell \frac{|Y_i \cap Z_i|}{|Y_i \cup Z_i|}.
$$

   - Полнота:

$$
\text{recall}(a, X) = \frac{1}{\ell} \sum_{i=1}^\ell \frac{|Y_i \cap Z_i|}{|Y_i|}.
$$



## Категориальные признаки

### Подходы к обработке

1. **Бинарное кодирование (One-Hot Encoding):**
   - Создаются $n$ индикаторов $g_j(x) = [f(x) = u_j]$.

2. **Бинарное кодирование с хэшированием:**
   - Значения признаков переводятся в $B$-размерное пространство с помощью хэш-функции.

3. **Счётчики:**
    - Считаются статистики по выборке:

$$
\text{counts}(u, X) = \sum_{(x, y) \in X} [f(x) = u], \quad \text{successes}_k(u, X) = \sum_{(x, y) \in X} [f(x) = u][y = k].
$$

    - Признаки оценивают вероятность $p(y = k | f(x))$.

## Решающие деревья и Рандомный лес

### Что такое решающие деревья?
Решающее дерево — это алгоритм машинного обучения, который представляет собой иерархическую структуру, использующую последовательные условия для разделения данных на группы. Каждый узел дерева отвечает за проверку условия на одном из признаков, а листовые узлы дают прогноз или решение.

Решающие деревья популярны благодаря их интерпретируемости и способности работать как с непрерывными, так и с категориальными данными. Они используются для задач классификации и регрессии.

### Принцип работы

1. **Разделение данных:**
   - Дерево строится путем рекурсивного разделения пространства признаков на основе условий. Каждое разделение основывается на максимизации "чистоты" полученных подмножеств данных.
   
2. **Оценка качества разделения:**
   - Для классификации используется **критерий чистоты**, например:
     - **Индекс Джини:**
       
$$
G = 1 - \sum_{k=1}^K p_k^2,
$$

где $p_k$ — доля объектов класса $k$.
     - **Энтропия:**

$$
H = - \sum_{k=1}^K p_k \log(p_k).
$$

   - Для регрессии используется **дисперсия** или **среднеквадратичная ошибка**:

$$ 
MSE = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y})^2.
$$

   
4. **Остановка роста дерева:**
   - Процесс деления останавливается, когда:
     - Достигнута минимальная глубина дерева.
     - В узле осталось меньше определенного числа объектов.
     - Новое разделение не улучшает качество модели.


### Преимущества решающих деревьев
1. Интерпретируемость: легко понять логику модели.
2. Поддержка смешанных данных (числовых и категориальных).
3. Нет необходимости в масштабировании признаков.
4. Хорошо работает с пропусками данных.

### Недостатки решающих деревьев
1. Склонность к переобучению (если дерево слишком глубокое).
2. Чувствительность к небольшим изменениям данных (нестабильность).
3. Ограниченная способность к обобщению для сложных задач.


### Обрезка (Pruning)
- **Предварительная обрезка (Pre-pruning):**
  - Ограничение роста дерева (например, максимальная глубина или минимальное количество объектов в узле).
- **Пост-обрезка (Post-pruning):**
  - Удаление лишних ветвей после полного построения дерева, если они не улучшают качество.

### Регуляризация
- Включение штрафа за сложность модели:
  - Ограничение глубины.
  - Установка минимального числа объектов в узле.
  - Ограничение минимального прироста качества для разделения.

### Что такое рандомный лес?
Рандомный лес — это ансамблевый метод, объединяющий множество решающих деревьев. Итоговый прогноз строится на основе голосования деревьев (для классификации) или усреднения их прогнозов (для регрессии).

### Основные идеи рандомного леса

1. **Бутстреппинг (Bagging):**
   - Каждое дерево обучается на случайной подвыборке исходных данных.
   - Это снижает корреляцию между деревьями и увеличивает стабильность модели.

2. **Случайный выбор признаков:**
   - Для каждого узла дерева случайным образом выбирается подмножество признаков, на которых строится разделение.
   - Это предотвращает доминирование сильных признаков.

3. **Ансамблевое обучение:**
   - Итоговый прогноз получается путем объединения прогнозов всех деревьев:
     - Для классификации: **большинство голосов**.
     - Для регрессии: **среднее значение**.

### Преимущества рандомного леса
1. Высокая точность на многих задачах.
2. Стабильность и устойчивость к шуму.
3. Устойчивость к переобучению благодаря ансамблевому подходу.
4. Поддержка работы с большим числом признаков.

### Недостатки рандомного леса
1. Потеря интерпретируемости (модель становится «черным ящиком»).
2. Высокая вычислительная сложность для больших наборов данных.
3. Модель может быть менее эффективной, если признаки несут слабую информацию.

### Важность признаков
- В рандомном лесе можно оценить значимость признаков:
  - **Decrease in Impurity:** оценка по уменьшению критерия (например, Джини) при разделении.
  - **Permutation Importance:** оценка по изменению качества модели при случайной перестановке значений признака.

### Настройка гиперпараметров

#### Для решающих деревьев:
- `max_depth`: максимальная глубина дерева.
- `min_samples_split`: минимальное количество объектов для разделения узла.
- `min_samples_leaf`: минимальное количество объектов в листе.
- `criterion`: функция оценки качества (например, `gini` или `entropy`).

#### Для рандомного леса:
- `n_estimators`: количество деревьев в ансамбле.
- `max_features`: число признаков для выбора при разделении.
- `bootstrap`: использование бутстреппинга (да/нет).
- `max_depth`, `min_samples_split`, `min_samples_leaf`: параметры деревьев внутри леса.

### Примеры применения

1. **Классификация:**
   - Определение заболеваний на основе медицинских данных.
   - Классификация изображений и текстов.
   - Предсказание оттока клиентов.

2. **Регрессия:**
   - Прогнозирование цен на недвижимость.
   - Оценка риска в кредитовании.
   - Прогнозирование спроса на товары.

3. **Выявление важности признаков:**
   - Анализ ключевых факторов, влияющих на целевую переменную.
   - Обнаружение нерелевантных или избыточных признаков.


### Практические рекомендации

1. **Для решающих деревьев:**
   - Начинайте с небольших глубин и увеличивайте их при необходимости.
   - Используйте кросс-валидацию для выбора оптимальных гиперпараметров.

2. **Для рандомного леса:**
   - Увеличивайте количество деревьев $n\_estimators$, пока качество не стабилизируется.
   - Используйте бутстреппинг и ограничение числа признаков $max\_features$ для повышения качества.

3. **Предобработка данных:**
   - Заполните пропуски или используйте подходы, устойчивые к пропускам.
   - Преобразуйте категориальные данные (например, с помощью one-hot encoding).

### Бустинг 
— это ансамблевый метод машинного обучения, который строит модель путем последовательного добавления слабых моделей (обычно решающих деревьев) с целью улучшения качества предсказаний.


### Введение в бустинг

### Основная идея бустинга
1. **Слабые модели:** В качестве базовых используются слабые алгоритмы, которые имеют качество чуть лучше случайного угадывания (например, мелкие решающие деревья).
2. **Итеративное обучение:** Новая модель настраивается так, чтобы исправлять ошибки предыдущих моделей.
3. **Ансамбль:** Итоговый прогноз получается путем взвешенного суммирования всех слабых моделей.



### Типы бустинга

### Адаптивный бустинг (AdaBoost)

1. **Алгоритм:**
   - На каждой итерации $t$ строится слабый классификатор $h_t(x)$.
   - Ошибки предыдущих моделей усиливаются за счет изменения весов объектов.

2. **Формулы:**
   - Начальные веса объектов:

$$ 
     w_i^{(1)} = \frac{1}{N}, 
$$

где $N$ — количество объектов.
   - Ошибка текущей модели:

$$ 
     \varepsilon_t = \frac{\sum_{i=1}^N w_i^{(t)} \cdot [y_i \neq h_t(x_i)]}{\sum_{i=1}^N w_i^{(t)}}.
$$

   - Коэффициент модели:

$$ 
     \alpha_t = \frac{1}{2} \ln\left(\frac{1 - \varepsilon_t}{\varepsilon_t}\right).
$$

   - Обновление весов:

$$
     w_i^{(t+1)} = w_i^{(t)} \cdot \exp\left(-\alpha_t \cdot y_i \cdot h_t(x_i)\right).
$$

3. Итоговый ансамбль:

$$
   H(x) = \text{sign} \left( \sum_{t=1}^T \alpha_t \cdot h_t(x) \right).
$$



### Градиентный бустинг (Gradient Boosting)

1. **Идея:**
   - Каждая новая модель минимизирует остатки (ошибки) предыдущих моделей.
   - Для регрессии минимизируется разница между истинными значениями и предсказаниями.
   - Для классификации минимизируется логарифмическая функция потерь.

2. **Формулы:**
   - Остатки на $t$-й итерации:
   
$$
     r_i^{(t)} = -\frac{\partial L(y_i, F(x_i))}{\partial F(x_i)},
$$

     где $L(y, F(x))$ — функция потерь.
   - Новый прогноз:
$$
     F_{t+1}(x) = F_t(x) + \eta \cdot h_t(x),
$$

где $\eta$ — шаг обучения, $h_t(x)$ — новое дерево.

3. Итоговый ансамбль:

$$
   F_T(x) = \sum_{t=1}^T \eta \cdot h_t(x).
$$



### Стохастический градиентный бустинг (Stochastic Gradient Boosting)

- Отличие от классического градиентного бустинга:
  - На каждой итерации используется случайная подвыборка объектов (например, 50%-70%).
  - Это снижает переобучение и увеличивает обобщающую способность.



### Категориальный бустинг (CatBoost)

1. **Особенности:**
   - Адаптирован для категориальных признаков.
   - Использует кодирование категориальных признаков на основе счётчиков с учётом информации о целевой переменной.

2. **Обучение:**
   - Упрощает обработку категориальных признаков.
   - Улучшает качество предсказания за счёт оптимизированных алгоритмов.



### Компоненты бустинга

### Базовые модели (слабые модели)
1. Обычно используются решающие деревья небольшой глубины (2-6 уровней).
2. Основные параметры:
   - `max_depth` — максимальная глубина дерева.
   - `min_samples_split` — минимальное количество объектов для разделения узла.

### Функции потерь
1. **Для регрессии:**
   - Среднеквадратичная ошибка (MSE):

$$
     L(y, F(x)) = \frac{1}{N} \sum_{i=1}^N (y_i - F(x_i))^2.
$$

   - MAE (средняя абсолютная ошибка):

$$
     L(y, F(x)) = \frac{1}{N} \sum_{i=1}^N |y_i - F(x_i)|.
$$

2. **Для классификации:**
   - Логарифмическая потеря (log-loss):
  
$$
     L(y, F(x)) = - \frac{1}{N} \sum_{i=1}^N \left( y_i \log p_i + (1 - y_i) \log (1 - p_i) \right).
$$



### Гиперпараметры бустинга

### Основные параметры
1. `n_estimators` — число деревьев (итераций).
   - Большее значение может улучшить качество, но увеличивает риск переобучения.
2. `learning_rate` — скорость обучения ($\eta$).
   - Типичные значения: $0.01 \leq \eta \leq 0.1$.
3. `max_depth` — глубина деревьев.
4. `subsample` — доля объектов для обучения на каждой итерации (для стохастического бустинга).



### Преимущества бустинга

1. Высокая точность на большинстве задач.
2. Гибкость и возможность адаптации под конкретные задачи.
3. Устойчивость к переобучению при правильной настройке гиперпараметров.



### Недостатки бустинга

1. Высокая вычислительная сложность.
2. Сложность настройки гиперпараметров.
3. Чувствительность к шуму в данных.



### Современные реализации бустинга

### XGBoost
1. Оптимизированная реализация градиентного бустинга.
2. Использует:
   - Параллельные вычисления.
   - Регуляризацию для борьбы с переобучением.

### LightGBM
1. Улучшенная версия бустинга с оптимизацией времени работы.
2. Использует метод "управляемого роста дерева" (Leaf-wise).

### CatBoost
1. Оптимизирован для категориальных признаков.
2. Предотвращает утечки данных в категориальных признаках за счет перекрёстного кодирования.

### Рекомендательные системы и ранжирование

Рекомендательные системы — это методы машинного обучения, предназначенные для персонализированного подбора контента, продуктов или услуг для пользователей. Ранжирование — это процесс сортировки объектов в соответствии с их релевантностью или важностью для конкретного запроса или пользователя.

### Типы рекомендательных систем

### Коллаборативная фильтрация (Collaborative Filtering)

1. **Основная идея:**
   - Основана на предположении, что пользователи с похожими предпочтениями будут предпочитать схожие объекты.

2. **Методы:**
   - **User-based:** рекомендации для пользователя на основе поведения похожих пользователей.
   - **Item-based:** рекомендации на основе схожести объектов.

3. **Алгоритмы:**
   - Косинусная близость:
   
$$
     \text{similarity}(u, v) = \frac{\sum_{i=1}^N r_{ui} \cdot r_{vi}}{\sqrt{\sum_{i=1}^N r_{ui}^2} \cdot \sqrt{\sum_{i=1}^N r_{vi}^2}},
$$ 

  где \( r_{ui} \) — рейтинг пользователя \( u \) для объекта \( i \).
   - Матричная факторизация (SVD):

$$
     R \approx U \cdot V^\top,
$$

где \( R \) — матрица рейтингов, \( U \) и \( V \) — латентные матрицы пользователей и объектов.

4. **Преимущества:**
   - Высокая точность при наличии достаточного объема данных.
   - Не требует информации о самих объектах.

5. **Недостатки:**
   - Проблема холодного старта для новых пользователей или объектов.
   - Высокая вычислительная сложность для больших данных.

### Контентная фильтрация (Content-Based Filtering)

1. **Основная идея:**
   - Рекомендации формируются на основе описания объектов и предпочтений пользователя.

2. **Методы:**
   - Создание профиля пользователя на основе взаимодействия с объектами.
   - Сравнение профиля пользователя с характеристиками объектов.

3. **Алгоритмы:**
   - TF-IDF (для текстовых данных):

$$
     \text{tf-idf}(t, d) = \text{tf}(t, d) \cdot \log\frac{N}{\text{df}(t)},
$$

     где \( \text{tf}(t, d) \) — частота термина \( t \) в документе \( d \), \( \text{df}(t) \) — количество документов, содержащих термин \( t \).
   - Косинусная близость для сравнения профилей.

4. **Преимущества:**
   - Хорошо работает для новых пользователей.
   - Простота и интерпретируемость.

5. **Недостатки:**
   - Ограничения по разнообразию рекомендаций (рекомендуются только похожие объекты).
   - Не учитываются предпочтения других пользователей.

### Гибридные системы (Hybrid Systems)

1. **Идея:**
   - Объединение коллаборативной и контентной фильтрации для повышения точности.

2. **Подходы:**
   - Комбинирование результатов двух моделей.
   - Обучение единой модели с учетом контентной и коллаборативной информации.


### Ранжирование

### Основная задача
Ранжирование — это упорядочивание объектов в соответствии с их релевантностью для конкретного пользователя или запроса.

### Типы задач ранжирования

1. **Pointwise:**
   - Каждый объект оценивается отдельно.
   - Пример: прогнозирование рейтинга (регрессия).
2. **Pairwise:**
   - Модели обучаются на парах объектов, предсказывая, какой объект более релевантен.
   - Пример: алгоритмы, использующие SVM или нейронные сети.
3. **Listwise:**
   - Учитывается полный список объектов и их относительные ранги.
   - Пример: оптимизация метрик ранжирования, таких как NDCG.

### Метрики оценки ранжирования

1. **DCG (Discounted Cumulative Gain):**

$$
   \text{DCG}_p = \sum_{i=1}^p \frac{2^{\text{rel}_i} - 1}{\log_2(i + 1)},
$$

где \( \text{rel}_i \) — релевантность объекта на позиции \( i \).

3. **NDCG (Normalized DCG):**

$$
   \text{NDCG}_p = \frac{\text{DCG}_p}{\text{IDCG}_p},
$$

где \( \text{IDCG}_p \) — идеальная DCG.

4. **Precision@K:**

$$
   \text{Precision@K} = \frac{\text{количество релевантных объектов в топ-K}}{K}.
$$

5. **MAP (Mean Average Precision):**

$$
   \text{MAP} = \frac{1}{N} \sum_{q=1}^N \frac{1}{m_q} \sum_{k=1}^{m_q} \text{Precision@k},
$$

где \( N \) — количество запросов, \( m_q \) — количество релевантных объектов для запроса \( q \).


### Современные подходы


### Алгоритмы ранжирования
1. **RankNet:** обучение нейронной сети для предсказания порядка в парах объектов.
2. **LambdaMART:** ансамблевый метод на основе градиентного бустинга, оптимизирующий NDCG.

### Проблемы и вызовы

1. **Холодный старт:**
   - Отсутствие данных для новых пользователей или объектов.
   - Решение: гибридные методы, использование контентных характеристик.

2. **Эффективность и масштабируемость:**
   - Обработка большого объема данных.
   - Решение: распределенные системы (Spark, Hadoop).

3. **Предвзятость и разнообразие:**
   - Слишком узкие рекомендации.
   - Решение: введение метрик разнообразия и случайности.



